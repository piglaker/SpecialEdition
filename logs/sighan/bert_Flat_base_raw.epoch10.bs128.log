***** Running training *****
  Num examples = 284196
  Num Epochs = 10
  Instantaneous batch size per device = 128
  Total train batch size (w. parallel, distributed & accumulation) = 384
  Gradient Accumulation steps = 1
  Total optimization steps = 7410
Read cache from cache/sighan_lattice_test.
  0%|          | 0/7410 [00:00<?, ?it/s]Traceback (most recent call last):
  File "bert_Flat.py", line 381, in <module>
    run()
  File "bert_Flat.py", line 313, in run
    train_result = trainer.train()
  File "/remote-home/xtzhang/anaconda3/envs/dophin/lib/python3.8/site-packages/transformers/trainer.py", line 1289, in train
    tr_loss += self.training_step(model, inputs)
  File "bert_Flat.py", line 139, in training_step
    loss, _ = self.compute_loss(model, inputs)
  File "bert_Flat.py", line 172, in compute_loss
    loss, logits = model(**inputs)
  File "/remote-home/xtzhang/anaconda3/envs/dophin/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/remote-home/xtzhang/anaconda3/envs/dophin/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/remote-home/xtzhang/anaconda3/envs/dophin/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/remote-home/xtzhang/anaconda3/envs/dophin/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/remote-home/xtzhang/anaconda3/envs/dophin/lib/python3.8/site-packages/torch/_utils.py", line 425, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/remote-home/xtzhang/anaconda3/envs/dophin/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/remote-home/xtzhang/anaconda3/envs/dophin/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/models/bert/modeling_bert_v2.py", line 1285, in forward
    outputs = self.bert(
  File "/remote-home/xtzhang/anaconda3/envs/dophin/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/models/bert/modeling_bert_v2.py", line 1229, in forward
    embedding_output,  rel_embedding, abs_embedding = self.embeddings(
  File "/remote-home/xtzhang/anaconda3/envs/dophin/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/models/bert/modeling_bert_v2.py", line 369, in forward
    rel_pos_embedding = self.dropout(rel_pos_embedding)
  File "/remote-home/xtzhang/anaconda3/envs/dophin/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/remote-home/xtzhang/anaconda3/envs/dophin/lib/python3.8/site-packages/torch/nn/modules/dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/remote-home/xtzhang/anaconda3/envs/dophin/lib/python3.8/site-packages/torch/nn/functional.py", line 1168, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
RuntimeError: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 10.92 GiB total capacity; 10.05 GiB already allocated; 95.38 MiB free; 10.06 GiB reserved in total by PyTorch)

  0%|          | 0/7410 [00:09<?, ?it/s]