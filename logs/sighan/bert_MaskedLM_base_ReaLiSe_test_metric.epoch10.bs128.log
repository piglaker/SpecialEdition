Thu Dec 23 08:14:34 UTC 2021
Thu Dec 23 08:14:41 UTC 2021
Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Using amp fp16 backend
***** Running training *****
  Num examples = 2000
  Num Epochs = 10
  Instantaneous batch size per device = 128
  Total train batch size (w. parallel, distributed & accumulation) = 128
  Gradient Accumulation steps = 1
  Total optimization steps = 160
Loading Dataset !
Hint: The Data You loading now is the preprocessed sighan from ReaLise, 
Loading Succeed !
  0%|          | 0/160 [00:00<?, ?it/s]  1%|          | 1/160 [00:01<02:45,  1.04s/it]  1%|▏         | 2/160 [00:01<01:35,  1.65it/s]  2%|▏         | 3/160 [00:01<01:16,  2.07it/s]  2%|▎         | 4/160 [00:02<01:06,  2.35it/s]  3%|▎         | 5/160 [00:02<01:01,  2.53it/s]  4%|▍         | 6/160 [00:02<00:57,  2.66it/s]  4%|▍         | 7/160 [00:03<00:55,  2.76it/s]  5%|▌         | 8/160 [00:03<00:53,  2.82it/s]  6%|▌         | 9/160 [00:03<00:52,  2.87it/s]  6%|▋         | 10/160 [00:04<00:51,  2.89it/s]  7%|▋         | 11/160 [00:04<00:51,  2.92it/s]  8%|▊         | 12/160 [00:04<00:48,  3.04it/s]  8%|▊         | 13/160 [00:05<00:48,  3.02it/s]  9%|▉         | 14/160 [00:05<00:48,  3.01it/s]  9%|▉         | 15/160 [00:05<00:48,  3.00it/s] 10%|█         | 16/160 [00:05<00:43,  3.33it/s]
  0%|          | 0/9 [00:00<?, ?it/s][A
 33%|███▎      | 3/9 [00:00<00:00, 19.86it/s][A
 56%|█████▌    | 5/9 [00:00<00:00, 11.54it/s][A
 78%|███████▊  | 7/9 [00:00<00:00, 10.54it/s][A
100%|██████████| 9/9 [00:00<00:00,  9.79it/s][A                                                
                                             [A 10%|█         | 16/160 [00:06<00:43,  3.33it/s]
100%|██████████| 9/9 [00:00<00:00,  9.79it/s][A
                                             [ASaving model checkpoint to ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-16
Configuration saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-16/config.json
Model weights saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-16/pytorch_model.bin
tokenizer config file saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-16/tokenizer_config.json
Special tokens file saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-16/special_tokens_map.json
 11%|█         | 17/160 [00:11<04:17,  1.80s/it] 11%|█▏        | 18/160 [00:11<03:12,  1.36s/it] 12%|█▏        | 19/160 [00:11<02:28,  1.05s/it] 12%|█▎        | 20/160 [00:12<01:57,  1.19it/s] 13%|█▎        | 21/160 [00:12<01:35,  1.46it/s] 14%|█▍        | 22/160 [00:12<01:20,  1.72it/s] 14%|█▍        | 23/160 [00:13<01:09,  1.97it/s] 15%|█▌        | 24/160 [00:13<01:01,  2.20it/s] 16%|█▌        | 25/160 [00:13<00:54,  2.46it/s] 16%|█▋        | 26/160 [00:14<00:51,  2.60it/s] 17%|█▋        | 27/160 [00:14<00:49,  2.71it/s] 18%|█▊        | 28/160 [00:14<00:47,  2.79it/s] 18%|█▊        | 29/160 [00:15<00:46,  2.85it/s] 19%|█▉        | 30/160 [00:15<00:44,  2.89it/s] 19%|█▉        | 31/160 [00:15<00:44,  2.93it/s] 20%|██        | 32/160 [00:16<00:38,  3.36it/s]{'eval_loss': 0.22575223445892334, 'eval_F1_score': 0.3021148035757184, 'eval_Precision': 0.3318584070795726, 'eval_Recall': 0.27726432532342377, 'eval_Metric_time': 0.028142452239990234, 'eval_runtime': 0.9512, 'eval_samples_per_second': 1156.431, 'eval_steps_per_second': 9.462, 'epoch': 1.0}

  0%|          | 0/9 [00:00<?, ?it/s][A
 33%|███▎      | 3/9 [00:00<00:00, 19.91it/s][A
 56%|█████▌    | 5/9 [00:00<00:00, 11.57it/s][A
 78%|███████▊  | 7/9 [00:00<00:00, 10.59it/s][A
100%|██████████| 9/9 [00:00<00:00,  9.82it/s][A                                                
                                             [A 20%|██        | 32/160 [00:16<00:38,  3.36it/s]
100%|██████████| 9/9 [00:00<00:00,  9.82it/s][A
                                             [ASaving model checkpoint to ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-32
Configuration saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-32/config.json
Model weights saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-32/pytorch_model.bin
tokenizer config file saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-32/tokenizer_config.json
Special tokens file saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-32/special_tokens_map.json
 21%|██        | 33/160 [00:21<03:36,  1.71s/it] 21%|██▏       | 34/160 [00:21<02:43,  1.29s/it] 22%|██▏       | 35/160 [00:21<02:05,  1.01s/it] 22%|██▎       | 36/160 [00:22<01:39,  1.24it/s] 23%|██▎       | 37/160 [00:22<01:21,  1.51it/s] 24%|██▍       | 38/160 [00:22<01:08,  1.77it/s] 24%|██▍       | 39/160 [00:23<00:59,  2.02it/s] 25%|██▌       | 40/160 [00:23<00:53,  2.24it/s] 26%|██▌       | 41/160 [00:23<00:48,  2.43it/s] 26%|██▋       | 42/160 [00:24<00:45,  2.58it/s] 27%|██▋       | 43/160 [00:24<00:43,  2.69it/s] 28%|██▊       | 44/160 [00:24<00:41,  2.79it/s] 28%|██▊       | 45/160 [00:25<00:40,  2.85it/s] 29%|██▉       | 46/160 [00:25<00:39,  2.87it/s] 29%|██▉       | 47/160 [00:25<00:39,  2.85it/s] 30%|███       | 48/160 [00:25<00:35,  3.20it/s]{'eval_loss': 0.20807380974292755, 'eval_F1_score': 0.3305954824967481, 'eval_Precision': 0.37182448036942917, 'eval_Recall': 0.2975970425138082, 'eval_Metric_time': 0.02716207504272461, 'eval_runtime': 0.9467, 'eval_samples_per_second': 1161.94, 'eval_steps_per_second': 9.507, 'epoch': 2.0}

  0%|          | 0/9 [00:00<?, ?it/s][A
 33%|███▎      | 3/9 [00:00<00:00, 19.90it/s][A
 56%|█████▌    | 5/9 [00:00<00:00, 11.57it/s][A
 78%|███████▊  | 7/9 [00:00<00:00, 10.20it/s][A
100%|██████████| 9/9 [00:00<00:00,  9.20it/s][A                                                
                                             [A 30%|███       | 48/160 [00:26<00:35,  3.20it/s]
100%|██████████| 9/9 [00:00<00:00,  9.20it/s][A
                                             [ASaving model checkpoint to ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-48
Configuration saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-48/config.json
Model weights saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-48/pytorch_model.bin
tokenizer config file saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-48/tokenizer_config.json
Special tokens file saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-48/special_tokens_map.json
 31%|███       | 49/160 [00:31<03:17,  1.77s/it] 31%|███▏      | 50/160 [00:31<02:27,  1.34s/it] 32%|███▏      | 51/160 [00:31<01:53,  1.04s/it] 32%|███▎      | 52/160 [00:32<01:29,  1.21it/s] 33%|███▎      | 53/160 [00:32<01:12,  1.47it/s] 34%|███▍      | 54/160 [00:32<01:01,  1.74it/s] 34%|███▍      | 55/160 [00:33<00:51,  2.04it/s] 35%|███▌      | 56/160 [00:33<00:46,  2.25it/s] 36%|███▌      | 57/160 [00:33<00:42,  2.44it/s] 36%|███▋      | 58/160 [00:34<00:39,  2.58it/s] 37%|███▋      | 59/160 [00:34<00:37,  2.69it/s] 38%|███▊      | 60/160 [00:34<00:35,  2.78it/s] 38%|███▊      | 61/160 [00:35<00:34,  2.84it/s] 39%|███▉      | 62/160 [00:35<00:33,  2.89it/s] 39%|███▉      | 63/160 [00:35<00:33,  2.92it/s] 40%|████      | 64/160 [00:35<00:29,  3.26it/s]{'eval_loss': 0.2140464037656784, 'eval_F1_score': 0.34196891186776257, 'eval_Precision': 0.38915094339613465, 'eval_Recall': 0.3049907578557661, 'eval_Metric_time': 0.03184342384338379, 'eval_runtime': 0.9945, 'eval_samples_per_second': 1106.077, 'eval_steps_per_second': 9.05, 'epoch': 3.0}

  0%|          | 0/9 [00:00<?, ?it/s][A
 33%|███▎      | 3/9 [00:00<00:00, 19.89it/s][A
 56%|█████▌    | 5/9 [00:00<00:00, 11.51it/s][A
 78%|███████▊  | 7/9 [00:00<00:00, 10.51it/s][A
100%|██████████| 9/9 [00:00<00:00,  9.78it/s][A                                                
                                             [A 40%|████      | 64/160 [00:36<00:29,  3.26it/s]
100%|██████████| 9/9 [00:00<00:00,  9.78it/s][A
                                             [ASaving model checkpoint to ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-64
Configuration saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-64/config.json
Model weights saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-64/pytorch_model.bin
tokenizer config file saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-64/tokenizer_config.json
Special tokens file saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-64/special_tokens_map.json
 41%|████      | 65/160 [00:41<02:56,  1.86s/it] 41%|████▏     | 66/160 [00:41<02:11,  1.40s/it] 42%|████▏     | 67/160 [00:42<01:40,  1.08s/it] 42%|████▎     | 68/160 [00:42<01:18,  1.17it/s] 43%|████▎     | 69/160 [00:42<01:03,  1.43it/s] 44%|████▍     | 70/160 [00:43<00:53,  1.69it/s] 44%|████▍     | 71/160 [00:43<00:46,  1.93it/s] 45%|████▌     | 72/160 [00:43<00:39,  2.22it/s] 46%|████▌     | 73/160 [00:44<00:35,  2.47it/s] 46%|████▋     | 74/160 [00:44<00:33,  2.57it/s] 47%|████▋     | 75/160 [00:44<00:31,  2.69it/s] 48%|████▊     | 76/160 [00:45<00:30,  2.78it/s] 48%|████▊     | 77/160 [00:45<00:29,  2.80it/s] 49%|████▉     | 78/160 [00:45<00:28,  2.83it/s] 49%|████▉     | 79/160 [00:46<00:28,  2.88it/s] 50%|█████     | 80/160 [00:46<00:24,  3.26it/s]{'eval_loss': 0.21445050835609436, 'eval_F1_score': 0.350154479868192, 'eval_Precision': 0.3953488372092104, 'eval_Recall': 0.31423290203321363, 'eval_Metric_time': 0.02721381187438965, 'eval_runtime': 0.9509, 'eval_samples_per_second': 1156.793, 'eval_steps_per_second': 9.465, 'epoch': 4.0}

  0%|          | 0/9 [00:00<?, ?it/s][A
 33%|███▎      | 3/9 [00:00<00:00, 19.68it/s][A
 56%|█████▌    | 5/9 [00:00<00:00, 11.45it/s][A
 78%|███████▊  | 7/9 [00:00<00:00, 10.49it/s][A
100%|██████████| 9/9 [00:00<00:00,  9.76it/s][A                                                
                                             [A 50%|█████     | 80/160 [00:47<00:24,  3.26it/s]
100%|██████████| 9/9 [00:00<00:00,  9.76it/s][A
                                             [ASaving model checkpoint to ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-80
Configuration saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-80/config.json
Model weights saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-80/pytorch_model.bin
tokenizer config file saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-80/tokenizer_config.json
Special tokens file saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-80/special_tokens_map.json
 51%|█████     | 81/160 [00:51<02:21,  1.79s/it] 51%|█████▏    | 82/160 [00:51<01:45,  1.35s/it] 52%|█████▏    | 83/160 [00:52<01:20,  1.05s/it] 52%|█████▎    | 84/160 [00:52<01:03,  1.19it/s] 53%|█████▎    | 85/160 [00:52<00:51,  1.46it/s] 54%|█████▍    | 86/160 [00:53<00:43,  1.71it/s] 54%|█████▍    | 87/160 [00:53<00:37,  1.96it/s] 55%|█████▌    | 88/160 [00:53<00:32,  2.18it/s] 56%|█████▌    | 89/160 [00:54<00:29,  2.37it/s] 56%|█████▋    | 90/160 [00:54<00:27,  2.52it/s] 57%|█████▋    | 91/160 [00:54<00:26,  2.64it/s] 57%|█████▊    | 92/160 [00:55<00:24,  2.82it/s] 58%|█████▊    | 93/160 [00:55<00:23,  2.87it/s] 59%|█████▉    | 94/160 [00:55<00:22,  2.91it/s] 59%|█████▉    | 95/160 [00:56<00:22,  2.93it/s] 60%|██████    | 96/160 [00:56<00:19,  3.27it/s]{'eval_loss': 0.2193746119737625, 'eval_F1_score': 0.3489795917872051, 'eval_Precision': 0.38952164009102747, 'eval_Recall': 0.3160813308687031, 'eval_Metric_time': 0.026742935180664062, 'eval_runtime': 0.9556, 'eval_samples_per_second': 1151.114, 'eval_steps_per_second': 9.418, 'epoch': 5.0}

  0%|          | 0/9 [00:00<?, ?it/s][A
 33%|███▎      | 3/9 [00:00<00:00, 19.79it/s][A
 56%|█████▌    | 5/9 [00:00<00:00, 11.53it/s][A
 78%|███████▊  | 7/9 [00:00<00:00, 10.51it/s][A
100%|██████████| 9/9 [00:00<00:00,  9.76it/s][A                                                
                                             [A 60%|██████    | 96/160 [00:57<00:19,  3.27it/s]
100%|██████████| 9/9 [00:00<00:00,  9.76it/s][A
                                             [ASaving model checkpoint to ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-96
Configuration saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-96/config.json
Model weights saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-96/pytorch_model.bin
tokenizer config file saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-96/tokenizer_config.json
Special tokens file saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-96/special_tokens_map.json
 61%|██████    | 97/160 [01:01<01:54,  1.82s/it] 61%|██████▏   | 98/160 [01:02<01:24,  1.36s/it] 62%|██████▏   | 99/160 [01:02<01:04,  1.06s/it] 62%|██████▎   | 100/160 [01:02<00:50,  1.19it/s] 63%|██████▎   | 101/160 [01:03<00:40,  1.45it/s] 64%|██████▍   | 102/160 [01:03<00:33,  1.75it/s] 64%|██████▍   | 103/160 [01:03<00:28,  2.00it/s] 65%|██████▌   | 104/160 [01:04<00:25,  2.22it/s] 66%|██████▌   | 105/160 [01:04<00:22,  2.41it/s] 66%|██████▋   | 106/160 [01:04<00:20,  2.65it/s] 67%|██████▋   | 107/160 [01:05<00:18,  2.84it/s] 68%|██████▊   | 108/160 [01:05<00:18,  2.88it/s] 68%|██████▊   | 109/160 [01:05<00:17,  2.91it/s] 69%|██████▉   | 110/160 [01:06<00:17,  2.93it/s] 69%|██████▉   | 111/160 [01:06<00:16,  2.95it/s] 70%|███████   | 112/160 [01:06<00:14,  3.24it/s]{'eval_loss': 0.22279737889766693, 'eval_F1_score': 0.3525773195382227, 'eval_Precision': 0.3986013986013057, 'eval_Recall': 0.3160813308687031, 'eval_Metric_time': 0.026782512664794922, 'eval_runtime': 0.9523, 'eval_samples_per_second': 1155.139, 'eval_steps_per_second': 9.451, 'epoch': 6.0}

  0%|          | 0/9 [00:00<?, ?it/s][A
 33%|███▎      | 3/9 [00:00<00:00, 19.66it/s][A
 56%|█████▌    | 5/9 [00:00<00:00, 11.49it/s][A
 78%|███████▊  | 7/9 [00:00<00:00, 10.51it/s][A
100%|██████████| 9/9 [00:00<00:00,  9.71it/s][A                                                 
                                             [A 70%|███████   | 112/160 [01:07<00:14,  3.24it/s]
100%|██████████| 9/9 [00:00<00:00,  9.71it/s][A
                                             [ASaving model checkpoint to ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-112
Configuration saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-112/config.json
Model weights saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-112/pytorch_model.bin
tokenizer config file saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-112/tokenizer_config.json
Special tokens file saved in ./tmp/sighan/bert_MaskedLM_base_ReaLiSe_test_metric.epoch10.bs128/checkpoint-112/special_tokens_map.json
 71%|███████   | 113/160 [01:12<01:30,  1.93s/it] 71%|███████▏  | 114/160 [01:12<01:06,  1.45s/it] 72%|███████▏  | 115/160 [01:12<00:50,  1.12s/it] 72%|███████▎  | 116/160 [01:13<00:38,  1.13it/s] 73%|███████▎  | 117/160 [01:13<00:30,  1.39it/s] 74%|███████▍  | 118/160 [01:13<00:25,  1.65it/s] 74%|███████▍  | 119/160 [01:14<00:21,  1.91it/s] 75%|███████▌  | 120/160 [01:14<00:18,  2.14it/s] 76%|███████▌  | 121/160 [01:15<00:16,  2.34it/s] 76%|███████▋  | 122/160 [01:15<00:15,  2.51it/s] 77%|███████▋  | 123/160 [01:15<00:14,  2.61it/s] 78%|███████▊  | 124/160 [01:16<00:13,  2.71it/s] 78%|███████▊  | 125/160 [01:16<00:12,  2.79it/s] 79%|███████▉  | 126/160 [01:16<00:12,  2.79it/s] 79%|███████▉  | 127/160 [01:17<00:11,  2.85it/s] 80%|████████  | 128/160 [01:17<00:09,  3.28it/s]{'eval_loss': 0.2235746830701828, 'eval_F1_score': 0.35427394433781006, 'eval_Precision': 0.399999999999907, 'eval_Recall': 0.31792975970419257, 'eval_Metric_time': 0.026938676834106445, 'eval_runtime': 0.9564, 'eval_samples_per_second': 1150.156, 'eval_steps_per_second': 9.41, 'epoch': 7.0}

  0%|          | 0/9 [00:00<?, ?it/s][A