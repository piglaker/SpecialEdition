{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "def read_csv(path):\n",
    "    result = []\n",
    "\n",
    "    with open(path) as f:\n",
    "        for line in f.readlines():\n",
    "            result.append(line)\n",
    "\n",
    "    return result\n",
    "\n",
    "def build_structure(throughs):\n",
    "    \"\"\"\n",
    "    #turn ['1 2 啥'] to {('1', '2'):'啥'}\n",
    "    #\n",
    "    #\n",
    "    \"\"\"\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for through in throughs:\n",
    "\n",
    "        through = through.split()\n",
    "\n",
    "        pointer = 0\n",
    "\n",
    "        catch = {}\n",
    "\n",
    "        #c++ style code for adapt \"2 3 好 的\" \n",
    "        while pointer + 3 <= len(through):\n",
    "\n",
    "            key = (through[pointer], through[pointer+1])# key like : (1,2) \n",
    "        \n",
    "            catch[key] = through[pointer+2]\n",
    "\n",
    "            while pointer + 3 < len(through) and not through[pointer+3].isdigit():\n",
    "\n",
    "                pointer += 1\n",
    "\n",
    "                catch[key] += through[pointer+2]\n",
    "            \n",
    "            pointer += 3\n",
    "\n",
    "        result.append(catch)\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### f1 score\n",
    "###\n",
    "#《Introduction to SIGHAN 2015 Bake-off for Chinese Spelling Check》\n",
    "# https://aclanthology.org/W15-3106.pdf\n",
    "#\n",
    "##\n",
    "\n",
    "def get_score(predict, target, debug = False):\n",
    "    \"\"\"\n",
    "    Detection \n",
    "    \"\"\"\n",
    "    print(\"*\"*5, \"Detection\", \"*\"*5)\n",
    "\n",
    "    tp, fp, fn, tn = 0, 0, 0, 0\n",
    "\n",
    "    tp_list, fp_list, fn_list = [], [], []\n",
    "\n",
    "    for i in tqdm(range(len(predict))):\n",
    "        \n",
    "        dict_pre, dict_true = predict[i], target[i]\n",
    "        #print(dict_pre, dict_true)\n",
    "\n",
    "        if not dict_true and dict_pre:\n",
    "            \"\"\"\n",
    "            Picked but Dont Need Pick\n",
    "            \"\"\"\n",
    "            fp += 1\n",
    "            fp_list.append(i)\n",
    "            continue\n",
    "        \n",
    "        if not dict_true and not dict_pre:\n",
    "            continue\n",
    "\n",
    "        flag = False\n",
    "        for key in dict_true.keys():\n",
    "            if not key in dict_pre.keys():\n",
    "                fn += 1\n",
    "                flag = True\n",
    "                fn_list.append(i)\n",
    "                break\n",
    "        if flag:\n",
    "            continue\n",
    "         \n",
    "        for key in dict_pre.keys():            \n",
    "            if key not in dict_true.keys():\n",
    "                \"\"\"\n",
    "                Need Pick but not Picked\n",
    "                \"\"\"\n",
    "                fn += 1\n",
    "                fn_list.append(i)\n",
    "                break\n",
    "        else:\n",
    "            \"\"\"\n",
    "            Picked and Need Pick\n",
    "            \"\"\"\n",
    "            tp += 1\n",
    "            tp_list.append(i)\n",
    "\n",
    "        \"\"\"\n",
    "        Unpick and Dont Need Pick\n",
    "        \"\"\"\n",
    "        #since f1 score dont need fn, so we wont calculate it\n",
    "        \n",
    "    print(\"TP: \",tp, \"FP: \", fp, \"FN: \", fn,)\n",
    "    \n",
    "    precision = tp / (tp + fp + 1e-10)\n",
    "\n",
    "    recall = tp / (tp + fn + 1e-10)\n",
    "\n",
    "    F1_score = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "\n",
    "    print(\"Precision: \", precision, \"Recall: \", recall)\n",
    "\n",
    "    print(\"F1_score: \", F1_score)\n",
    "\n",
    "    return F1_score, tp_list, fp_list, fn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### f1 score\n",
    "###\n",
    "#《Introduction to SIGHAN 2015 Bake-off for Chinese Spelling Check》\n",
    "# https://aclanthology.org/W15-3106.pdf\n",
    "#\n",
    "##\n",
    "\n",
    "def get_score_correction(predict, target):\n",
    "    \"\"\"\n",
    "    Correction Level\n",
    "    \"\"\"\n",
    "    print(\"*\"*5, \"Correction\", \"*\"*5)\n",
    "\n",
    "    tp, fp, fn, tn = 0, 0, 0, 0\n",
    "\n",
    "    tp_list, fp_list, fn_list = [], [], []\n",
    "\n",
    "    for i in tqdm(range(len(predict))):\n",
    "\n",
    "        dict_pre, dict_true = predict[i], target[i]\n",
    "        #print(dict_pre, dict_true)\n",
    "\n",
    "        if not dict_true and dict_pre:\n",
    "            \"\"\"\n",
    "            Picked but Dont Need Pick\n",
    "            \"\"\"\n",
    "            fp += 1\n",
    "            fp_list.append(i)\n",
    "            continue\n",
    "        \n",
    "        if not dict_true and not dict_pre:\n",
    "            continue\n",
    "\n",
    "        flag = False\n",
    "        for key in dict_true.keys():\n",
    "            if not key in dict_pre.keys():\n",
    "                fn += 1\n",
    "                flag = True\n",
    "                fn_list.append(i)\n",
    "                break\n",
    "        if flag:\n",
    "            continue\n",
    "\n",
    "        for key in dict_pre.keys():            \n",
    "            if key not in dict_true.keys():\n",
    "                \"\"\"\n",
    "                Need Pick but Not Picked\n",
    "                \"\"\"\n",
    "                fn += 1\n",
    "                fn_list.append(i)\n",
    "                break\n",
    "            elif dict_pre[key] != dict_true[key]:\n",
    "                fn += 1\n",
    "                fn_list.append(i)\n",
    "                break\n",
    "        else:\n",
    "            \"\"\"\n",
    "            Picked and Need Pick\n",
    "            \"\"\"\n",
    "            tp += 1\n",
    "            tp_list.append(i)\n",
    "            \n",
    "        #since f1 score dont need fn, so we wont calculate it\n",
    "        \n",
    "    print(\"TP: \",tp, \"FP: \", fp, \"FN: \", fn,)\n",
    "    \n",
    "    precision = tp / (tp + fp + 1e-10)\n",
    "\n",
    "    recall = tp / (tp + fn + 1e-10)\n",
    "\n",
    "    F1_score = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "\n",
    "    print(\"Precision: \", precision, \"Recall: \", recall)\n",
    "\n",
    "    print(\"F1_score: \", F1_score)\n",
    "\n",
    "    return F1_score, tp_list, fp_list, fn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sighan15 test through character level\n",
    "#predictions_path = \"../../tmp/tst-csc-test/generated_predictions.txt\"\n",
    "#target_path = \"../../data/rawdata/sighan/valid.through\"\n",
    "\n",
    "#predictions, target = read_csv(predictions_path), read_csv(target_path)\n",
    "\n",
    "#structured_predictions, structured_target = build_structure(predictions), build_structure(target)\n",
    "\n",
    "#get_score(structured_predictions, structured_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Detection *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:00<00:00, 349525.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  379 FP:  133 FN:  163\n",
      "Precision:  0.7402343749998553 Recall:  0.6992619926197972\n",
      "F1_score:  0.7191650853388982\n",
      "***** Correction *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:00<00:00, 348706.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  361 FP:  133 FN:  181\n",
      "Precision:  0.7307692307690828 Recall:  0.6660516605164822\n",
      "F1_score:  0.6969111968611696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#sighan15 test\n",
    "predictions_path = \"../../tmp/sighan_seq/generated_predictions.through\"\n",
    "target_path = \"../../data/rawdata/sighan/valid.through\"\n",
    "\n",
    "predictions, target = read_csv(predictions_path), read_csv(target_path)\n",
    "\n",
    "structured_predictions, structured_target = build_structure(predictions), build_structure(target)\n",
    "\n",
    "_ = get_score(structured_predictions, structured_target)\n",
    "\n",
    "_ = get_score_correction(structured_predictions, structured_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Detection *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:00<00:00, 329223.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  389 FP:  133 FN:  153\n",
      "Precision:  0.7452107279692058 Recall:  0.7177121771216387\n",
      "F1_score:  0.7312030074686772\n",
      "***** Correction *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:00<00:00, 307766.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  371 FP:  133 FN:  171\n",
      "Precision:  0.736111111110965 Recall:  0.6845018450183238\n",
      "F1_score:  0.7093690248065269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#sighan15 test\n",
    "predictions_path = \"../../tmp/sighan_seq/generated_predictions_8884.through\"\n",
    "target_path = \"../../data/rawdata/sighan/valid.through\"\n",
    "\n",
    "predictions, target = read_csv(predictions_path), read_csv(target_path)\n",
    "\n",
    "structured_predictions, structured_target = build_structure(predictions), build_structure(target)\n",
    "\n",
    "_ = get_score(structured_predictions, structured_target)\n",
    "\n",
    "_ = get_score_correction(structured_predictions, structured_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Detection *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:00<00:00, 626270.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  377 FP:  137 FN:  165\n",
      "Precision:  0.7334630350193125 Recall:  0.6955719557194288\n",
      "F1_score:  0.7140151514650513\n",
      "***** Correction *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:00<00:00, 587961.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  359 FP:  137 FN:  183\n",
      "Precision:  0.7237903225804992 Recall:  0.662361623616114\n",
      "F1_score:  0.6917148361734717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#sighan15 test\n",
    "predictions_path = \"../../tmp/sighan_seq/generated_predictions_.through\"\n",
    "target_path = \"../../data/rawdata/sighan/valid.through\"\n",
    "\n",
    "predictions, target = read_csv(predictions_path), read_csv(target_path)\n",
    "\n",
    "structured_predictions, structured_target = build_structure(predictions), build_structure(target)\n",
    "\n",
    "_ = get_score(structured_predictions, structured_target)\n",
    "\n",
    "_ = get_score_correction(structured_predictions, structured_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Detection *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1099/1099 [00:00<00:00, 316763.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  368 FP:  125 FN:  173\n",
      "Precision:  0.7464503042594834 Recall:  0.6802218114601329\n",
      "F1_score:  0.711798839408384\n",
      "***** Correction *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1099/1099 [00:00<00:00, 326454.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  342 FP:  125 FN:  199\n",
      "Precision:  0.7323340471090509 Recall:  0.6321626617374062\n",
      "F1_score:  0.6785714285215635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#sighan15 test 20 epoch 3090 batch_size 64 \n",
    "predictions_path = \"../../tmp/bart_sighan_seq/generated_predictions.through\"\n",
    "target_path = \"../../data/rawdata/sighan/valid.through\"\n",
    "\n",
    "predictions, target = read_csv(predictions_path), read_csv(target_path)\n",
    "\n",
    "structured_predictions, structured_target = build_structure(predictions), build_structure(target)\n",
    "\n",
    "_ = get_score(structured_predictions, structured_target)\n",
    "\n",
    "_ = get_score_correction(structured_predictions, structured_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Detection *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1099/1099 [00:00<00:00, 321625.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  386 FP:  138 FN:  155\n",
      "Precision:  0.7366412213739052 Recall:  0.7134935304989438\n",
      "F1_score:  0.7248826290578577\n",
      "***** Correction *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1099/1099 [00:00<00:00, 303179.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  361 FP:  138 FN:  180\n",
      "Precision:  0.7234468937874302 Recall:  0.6672828096117065\n",
      "F1_score:  0.6942307691807174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#sighan15 test 10 epoch 3090 batch_sizer 64\n",
    "predictions_path = \"../../tmp/bart_sighan_seq_10epoch/generated_predictions.through\"\n",
    "target_path = \"../../data/rawdata/sighan/valid.through\"\n",
    "\n",
    "predictions, target = read_csv(predictions_path), read_csv(target_path)\n",
    "\n",
    "structured_predictions, structured_target = build_structure(predictions), build_structure(target)\n",
    "\n",
    "_ = get_score(structured_predictions, structured_target)\n",
    "\n",
    "_ = get_score_correction(structured_predictions, structured_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Detection *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1061/1061 [00:00<00:00, 373366.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  248 FP:  232 FN:  272\n",
      "Precision:  0.516666666666559 Recall:  0.4769230769229852\n",
      "F1_score:  0.4959999999499808\n",
      "***** Correction *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1061/1061 [00:00<00:00, 375540.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  240 FP:  232 FN:  280\n",
      "Precision:  0.5084745762710787 Recall:  0.46153846153837275\n",
      "F1_score:  0.483870967691955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#sighan14 test\n",
    "predictions_path = \"../../tmp/sighan_seq/generated_predictions14.through\"\n",
    "target_path = \"../../data/rawdata/sighan/valid14.through\"\n",
    "\n",
    "predictions, target = read_csv(predictions_path), read_csv(target_path)\n",
    "\n",
    "structured_predictions, structured_target = build_structure(predictions), build_structure(target)\n",
    "\n",
    "_ = get_score(structured_predictions, structured_target)\n",
    "\n",
    "_ = get_score_correction(structured_predictions, structured_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_get_score(source, predictions, target):\n",
    "    sources, preds, tgts = [ \"\".join(src.split()) for src in source ], [ \"\".join(pre.split()) for pre in predictions ], [ \"\".join(tgt.split()) for tgt in target ] \n",
    "\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "\n",
    "    for i in range(len(sources)):\n",
    "        source, pred, label = sources[i], preds[i], tgts[i] \n",
    "  \n",
    "\n",
    "        if source == label:\n",
    "            if (pred == label):\n",
    "                pass\n",
    "            else:\n",
    "                fp += 1 \n",
    "        else :\n",
    "            if pred == label:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "                      \n",
    "    precision = tp / (tp + fp + 1e-10)\n",
    "\n",
    "    recall = tp / (tp + fn + 1e-10)\n",
    "\n",
    "    F1_score = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "\n",
    "    print(\"Precision: \", precision, \"Recall: \", recall)\n",
    "\n",
    "    print(\"F1_score: \", F1_score)\n",
    "\n",
    "    return {\"F1_score\": float(F1_score)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你 好! 我 是 张 爱 文 。\n",
      " 你好!我是张爱文。\n",
      "\n",
      "Precision:  0.7296747967478192 Recall:  0.662361623616114\n",
      "F1_score:  0.694390715617294\n"
     ]
    }
   ],
   "source": [
    "#sighan test\n",
    "sources_path = \"../../data/rawdata/sighan/test.src\"\n",
    "predictions_path = \"../../tmp/sighan/bart_seq2seq_eval.epoch10.bs32/generated_predictions.txt\"\n",
    "targets_path = \"../../data/rawdata/sighan/test.tgt\"\n",
    "\n",
    "sources, predictions, targets = read_csv(sources_path), read_csv(predictions_path), read_csv(targets_path)\n",
    "\n",
    "print(predictions[0], target[0])\n",
    "\n",
    "_ = better_get_score(sources, predictions, targets)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5798d1b89faf9fad5f596318b99ae69e82e8b63ab102e599c8ecfb07b8dff05"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('dophin': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
