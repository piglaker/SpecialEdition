{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils.io import read_csv, load_json, write_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strQ2B(ustring):\n",
    "    \"\"\"全角转半角\"\"\"\n",
    "    rstring = \"\"\n",
    "    for uchar in ustring:\n",
    "        inside_code=ord(uchar)\n",
    "        if inside_code == 12288:                              #全角空格直接转换            \n",
    "            inside_code = 32 \n",
    "        elif (inside_code >= 65281 and inside_code <= 65374): #全角字符（除空格）根据关系转化\n",
    "            inside_code -= 65248\n",
    "\n",
    "        rstring += chr(inside_code)\n",
    "    return rstring\n",
    "\n",
    "def get_sighan_from_json():\n",
    "\n",
    "    all_data = {\n",
    "        \"train\":None,\n",
    "        \"dev\":None,\n",
    "        \"test\":None,\n",
    "        \"test14\":None,\n",
    "        \"test15\":None,\n",
    "    }\n",
    "    data_dir = \"../data/rawdata/sighan/csc/\"\n",
    "\n",
    "    train_file1 = os.path.join(data_dir, \"train_dev.json\")\n",
    "    train_file2 = os.path.join(data_dir, \"train131415.json\") \n",
    "    test14_file = os.path.join(data_dir, \"test14.json\")\n",
    "    test15_file = os.path.join(data_dir, \"test15.json\")\n",
    "\n",
    "    all_data[\"train\"] = load_json(train_file1)\n",
    "    all_data[\"train\"].extend(load_json(train_file2))\n",
    "\n",
    "    all_data[\"train\"] = all_data[\"train\"]\n",
    "\n",
    "    all_data[\"valid14\"] = load_json(test14_file)\n",
    "    all_data[\"valid\"] = load_json(test15_file)\n",
    "    #all_data[\"test\"].extend(load_json(test15_file))\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def json2list(data, need_preprocess):\n",
    "    source, target, ids = [], [], []\n",
    "\n",
    "    for element in data:\n",
    "\n",
    "        if need_preprocess:\n",
    "            source.append(element[\"original_text\"])\n",
    "            target.append(element[\"correct_text\"])\n",
    "            ids.apoend(element[\"wrong_ids\"])\n",
    "        else:\n",
    "            source.append(strQ2B((element[\"original_text\"])))\n",
    "            target.append(strQ2B((element[\"correct_text\"])))\n",
    "            ids.append(element[\"wrong_ids\"])\n",
    "\n",
    "    return source, target, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_sighan_from_json()\n",
    "\n",
    "source, target, ids = json2list(data[\"train\"], False)\n",
    "#source, target, ids = json2list(data[\"valid\"], False)\n",
    "\n",
    "raw_bert_preds = read_csv(\"/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/tmp/sighan/bert_MaskedLM_base_std.epoch10.bs128/generated_predictions.txt\")\n",
    "#raw_bert_preds = read_csv(\"/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/tmp/sighan/bert_MaskedLM_base_raw.epoch10.bs128/generated_predictions.txt\")\n",
    "\n",
    "#proto_preds = read_csv(\"/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/tmp/sighan/bshert_Flat_std_char.epoch10.bs16/generated_predictions.txt\")\n",
    "proto_preds = read_csv(\"/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/tmp/sighan/bert_MaskedLM_v2_std.epoch10.bs32/generated_predictions.txt\")\n",
    "#proto_preds = read_csv(\"/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/tmp/sighan/bert_MaskedLM_v2_std_mask.epoch20.bs32/generated_predictions.txt\")\n",
    "#proto_preds = read_csv(\"./no_mask_preds.txt\")\n",
    "#proto_preds = read_csv(\"./no_mask_preds_super.txt\")\n",
    "#proto_preds = read_csv(\"./no_mask_preds_overfit.txt\")\n",
    "#proto_preds = read_csv(\"./no_mask_bert_preds_overfit.txt\")\n",
    "\n",
    "\n",
    "for i in range(len(source[:1100])):\n",
    "    #raw_bert_preds[i] = \"\".join(raw_bert_preds[i].split())[:len(source[i])]\n",
    "    proto_preds[i] = \"\".join(proto_preds[i].split())[:len(source[i])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 1100 1100 1100\n"
     ]
    }
   ],
   "source": [
    "print(len(source), len(raw_bert_preds), len(target), len(proto_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to(\"./newest_preds.txt\", \"\\n\".join(proto_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_cor = []\n",
    "no_need_cor = []\n",
    "\n",
    "def get_cor(source, target):\n",
    "    return [ (j, target[j]) for j in range(len(target)) if target[j] != source[j]]\n",
    "\n",
    "\n",
    "truth_cor_host, bert_cor_host, proto_cor_host = [], [], [] \n",
    "\n",
    "for i in range(len(source)):\n",
    "    truth_cor, bert_cor, proto_cor = get_cor(source[i], target[i]), get_cor(source[i], raw_bert_preds[i]), get_cor(source[i], proto_preds[i])\n",
    "    \n",
    "    truth_cor_host.append(truth_cor)\n",
    "    bert_cor_host.append(bert_cor)\n",
    "    proto_cor_host.append(proto_cor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [(9, '友')], [], [(2, '起')], [(14, '舞')], [], [], [(3, '餐')], [(0, '走')], []] [[], [(9, '友')], [], [(2, '起')], [(14, '舞')], [], [], [(3, '餐')], [(0, '走')], []]\n"
     ]
    }
   ],
   "source": [
    "print(truth_cor_host[0:10], bert_cor_host[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "你好!我是张爱文。\n",
      "怎么\n",
      "面见\n",
      "汉字\n",
      "心情\n",
      "唠叨\n",
      "拜托\n",
      "存到\n",
      "不是\n",
      "看著\n",
      "看著\n",
      "10\n",
      "[83, 90, 164, 700, 807, 833, 838, 1060, 1085, 1085]\n"
     ]
    }
   ],
   "source": [
    "#check if lexcions perform\n",
    "yjzheng_result = ['小鸡', '记得', '糊涂', '订位', '怎么', '面见', '弟弟', '炒饭', '汉字', '那店', '八点钟', '这样', '迟到', '很饱', '迟到', '迟到', '安静', '一点', '妈妈', '吃饭', '时候', '希望', '简讯', '那里', '诉取', '不半工', '哪些', '上半', '上半', '轻松', '消息', '与此同时', '这种', '权利', '优家', '失业', '心情', '减少', '著迷', '家长', '唠叨', '影响', '睡觉', '拜托', '存到', '年轻', '威胁', '我们', '回覆', '墙壁', '他们', '这是', '现在', '很忙', '不怎么', '试试看', '录影机', '哪个', '哪个', '不是', '再加', '该不该', '看著', '看著', '有装', '教书', '记录']\n",
    "print(len(yjzheng_result))\n",
    "print(source[0])\n",
    "\n",
    "yjzheng_ids = []\n",
    "for i in range(len(source)):\n",
    "    for j in yjzheng_result:\n",
    "        if re.search(j, target[i]) and (not re.search(j, source[i])) and (not re.search(j, raw_bert_preds[i])) and (re.search(j, proto_preds[i])):\n",
    "            print(j)\n",
    "            yjzheng_ids.append(i)\n",
    "\n",
    "print(len(yjzheng_ids))\n",
    "print(yjzheng_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better:  61\n",
      "worse:  56\n"
     ]
    }
   ],
   "source": [
    "#样本条数 proto比bert好的\n",
    "\n",
    "proto_better_than_bert = 0\n",
    "\n",
    "proto_worse_than_bert = 0\n",
    "\n",
    "def isequal(truth_cor, now_cor):\n",
    "    #cor: [(index, char), ...]\n",
    "    #if equal\n",
    "    if len(truth_cor) != len(now_cor):\n",
    "        return False\n",
    "\n",
    "    for i in range(len(truth_cor)):\n",
    "        if truth_cor[i] != now_cor[i]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "better_list = []\n",
    "worse_list = []\n",
    "\n",
    "for i in range(len(truth_cor_host)):\n",
    "    if isequal(proto_cor_host[i], truth_cor_host[i]) and (not isequal(bert_cor_host[i], truth_cor_host[i])):\n",
    "        proto_better_than_bert += 1\n",
    "        better_list.append(i)\n",
    "        #print(source[i])\n",
    "    elif (not isequal(proto_cor_host[i], truth_cor_host[i])) and (isequal(bert_cor_host[i], truth_cor_host[i])):\n",
    "        proto_worse_than_bert += 1\n",
    "        worse_list.append(i)\n",
    "    #break\n",
    "print(\"better: \", proto_better_than_bert)\n",
    "print(\"worse: \", proto_worse_than_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_show(name, ids_list, source, truth_cor_host, bert_cor_host, proto_cor_host):\n",
    "    tmp = \"\"\n",
    "\n",
    "    for i in ids_list:\n",
    "        first = source[i] + \"\\n\"\n",
    "        second = [\"  \"] * len(source[i]) + [\"\\n\"]\n",
    "        for cor in truth_cor_host[i]:\n",
    "            second[cor[0]] = cor[1]\n",
    "\n",
    "        third = [\"  \"] * len(source[i]) + [\"\\n\"]\n",
    "        for cor in bert_cor_host[i]:\n",
    "            third[cor[0]] = cor[1]\n",
    "\n",
    "        fourth = [\"  \"] * len(source[i]) + [\"\\n\"]\n",
    "        for cor in proto_cor_host[i]:\n",
    "            fourth[cor[0]] = cor[1]\n",
    "        \n",
    "        tmp += \"\".join(first) + \"\".join(second) + \"\".join(third) + \"\".join(fourth) + \"\\n\"\n",
    "\n",
    "    write_to(\"tmp_analysis_\" + name + \".txt\", tmp)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_show(\"better_v4\", better_list, source ,truth_cor_host, bert_cor_host, proto_cor_host)\n",
    "\n",
    "short_show(\"worse_v4\", worse_list, source, truth_cor_host, bert_cor_host, proto_cor_host)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_visuial(sources, preds, labels):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        tp, fp, fn = 0, 0, 0\n",
    "\n",
    "        sent_p, sent_n = 0, 0\n",
    "\n",
    "        for i in range(len(sources)):\n",
    "            \n",
    "            source, pred, label = sources[i], preds[i], labels[i]\n",
    "            \n",
    "            source = source[:len(label)]\n",
    "            pred = pred[:len(label)]\n",
    "\n",
    "            if not (pred == source):\n",
    "                sent_p += 1\n",
    "                if (pred == label):\n",
    "                    tp += 1\n",
    "\n",
    "            if (label != source):\n",
    "                sent_n += 1\n",
    "\n",
    "        precision = tp / sent_p\n",
    "        recall = tp / sent_n\n",
    "        F1_score = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "\n",
    "        print(\"precision: \", precision, \"recall: \", recall, \"F1_score: \", F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.7040816326530612 recall:  0.7638376383763837 F1_score:  0.7327433627819413\n"
     ]
    }
   ],
   "source": [
    "compute_metrics_visuial(source, raw_bert_preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.0 recall:  0.0 F1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "compute_metrics_visuial(source[:1100], proto_preds, target[:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint = \"\"\n",
    "\n",
    "for i in range(len(source)):\n",
    "    first = source[i] + \"\\n\"\n",
    "    second = [\"  \"] * len(source[i]) + [\"\\n\"]\n",
    "    if truth_cor_host[i]:\n",
    "        for cor in truth_cor_host[i]:\n",
    "            second[cor[0]] = cor[1]\n",
    "    \n",
    "    third = [\"  \"] * len(source[i]) + [\"\\n\"]\n",
    "    if bert_cor_host[i]:\n",
    "        for cor in bert_cor_host[i]:\n",
    "            third[cor[0]] = cor[1]\n",
    "\n",
    "    fourth = [\"  \"] * len(source[i]) + [\"\\n\"]\n",
    "    if proto_cor_host[i]:\n",
    "        for cor in proto_cor_host[i]:\n",
    "            fourth[cor[0]] = cor[1]\n",
    "    joint += \"\".join(first) + \"\".join(second) + \"\".join(third) + \"\".join(fourth) + \"\\n\"\n",
    "\n",
    "\n",
    "write_to(\"tmp_analysis_bert_MLM_v4_mask.txt\", joint)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e2dc701bf398b464ce69644f23ea143adca83783263e47d39149d5b90225121"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('117': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
