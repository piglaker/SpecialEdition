{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils.io import read_csv, load_json, write_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strQ2B(ustring):\n",
    "    \"\"\"全角转半角\"\"\"\n",
    "    rstring = \"\"\n",
    "    for uchar in ustring:\n",
    "        inside_code=ord(uchar)\n",
    "        if inside_code == 12288:                              #全角空格直接转换            \n",
    "            inside_code = 32 \n",
    "        elif (inside_code >= 65281 and inside_code <= 65374): #全角字符（除空格）根据关系转化\n",
    "            inside_code -= 65248\n",
    "\n",
    "        rstring += chr(inside_code)\n",
    "    return rstring\n",
    "\n",
    "def get_sighan_from_json():\n",
    "\n",
    "    all_data = {\n",
    "        \"train\":None,\n",
    "        \"dev\":None,\n",
    "        \"test\":None,\n",
    "        \"test14\":None,\n",
    "        \"test15\":None,\n",
    "    }\n",
    "    data_dir = \"../data/rawdata/sighan/csc/\"\n",
    "\n",
    "    train_file1 = os.path.join(data_dir, \"train_dev.json\")\n",
    "    train_file2 = os.path.join(data_dir, \"train131415.json\") \n",
    "    test14_file = os.path.join(data_dir, \"test14.json\")\n",
    "    test15_file = os.path.join(data_dir, \"test15.json\")\n",
    "\n",
    "    all_data[\"train\"] = load_json(train_file1)\n",
    "    all_data[\"train\"].extend(load_json(train_file2))\n",
    "\n",
    "    all_data[\"train\"] = all_data[\"train\"]\n",
    "\n",
    "    all_data[\"valid14\"] = load_json(test14_file)\n",
    "    all_data[\"valid\"] = load_json(test15_file)\n",
    "    #all_data[\"test\"].extend(load_json(test15_file))\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def json2list(data, need_preprocess):\n",
    "    source, target, ids = [], [], []\n",
    "\n",
    "    for element in data:\n",
    "\n",
    "        if need_preprocess:\n",
    "            source.append(element[\"original_text\"])\n",
    "            target.append(element[\"correct_text\"])\n",
    "            ids.apoend(element[\"wrong_ids\"])\n",
    "        else:\n",
    "            source.append(strQ2B((element[\"original_text\"])))\n",
    "            target.append(strQ2B((element[\"correct_text\"])))\n",
    "            ids.append(element[\"wrong_ids\"])\n",
    "\n",
    "    return source, target, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_sighan_from_json()\n",
    "\n",
    "source, target, ids = json2list(data[\"valid\"], False)\n",
    "\n",
    "raw_bert_preds = read_csv(\"/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/tmp/sighan/bert_MaskedLM_base_std.epoch10.bs128/generated_predictions.txt\")\n",
    "\n",
    "#proto_preds = read_csv(\"/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/tmp/sighan/bshert_Flat_std_char.epoch10.bs16/generated_predictions.txt\")\n",
    "proto_preds = read_csv(\"/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/tmp/sighan/bert_MaskedLM_v2_std.epoch10.bs32/generated_predictions.txt\")\n",
    "\n",
    "for i in range(len(source)):\n",
    "    raw_bert_preds[i] = \"\".join(raw_bert_preds[i].split())[:len(source[i])]\n",
    "    proto_preds[i] = \"\".join(proto_preds[i].split())[:len(source[i])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 1100 1100 1100\n"
     ]
    }
   ],
   "source": [
    "print(len(source), len(raw_bert_preds), len(target), len(proto_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to(\"./newest_preds.txt\", \"\\n\".join(proto_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_cor = []\n",
    "no_need_cor = []\n",
    "\n",
    "def get_cor(source, target):\n",
    "    return [ (j, target[j]) for j in range(len(target)) if target[j] != source[j]]\n",
    "\n",
    "\n",
    "truth_cor_host, bert_cor_host, proto_cor_host = [], [], [] \n",
    "\n",
    "for i in range(len(source)):\n",
    "    truth_cor, bert_cor, proto_cor = get_cor(source[i], target[i]), get_cor(source[i], raw_bert_preds[i]), get_cor(source[i], proto_preds[i])\n",
    "    \n",
    "    truth_cor_host.append(truth_cor)\n",
    "    bert_cor_host.append(bert_cor)\n",
    "    proto_cor_host.append(proto_cor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(truth_cor_host[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint = \"\"\n",
    "\n",
    "for i in range(len(source)):\n",
    "    first = source[i] + \"\\n\"\n",
    "    second = [\"  \"] * len(source[i]) + [\"\\n\"]\n",
    "    if truth_cor_host[i]:\n",
    "        for cor in truth_cor_host[i]:\n",
    "            second[cor[0]] = cor[1]\n",
    "    \n",
    "    third = [\"  \"] * len(source[i]) + [\"\\n\"]\n",
    "    if bert_cor_host[i]:\n",
    "        for cor in bert_cor_host[i]:\n",
    "            third[cor[0]] = cor[1]\n",
    "\n",
    "    fourth = [\"  \"] * len(source[i]) + [\"\\n\"]\n",
    "    if proto_cor_host[i]:\n",
    "        for cor in proto_cor_host[i]:\n",
    "            fourth[cor[0]] = cor[1]\n",
    "    joint += \"\".join(first) + \"\".join(second) + \"\".join(third) + \"\".join(fourth) + \"\\n\"\n",
    "\n",
    "\n",
    "write_to(\"tmp_analysis_bert_MLM_v2.txt\", joint)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e2dc701bf398b464ce69644f23ea143adca83783263e47d39149d5b90225121"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('117': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
