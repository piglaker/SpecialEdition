{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/remote-home/share/yjzheng/cscdata/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class mydataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/rawdata/sighan/realise/data/\"\n",
    "import pickle\n",
    "train_dataset = pickle.load(open(path + \"trainall.times2_plus.pkl\", \"rb\"))\n",
    "eval_dataset = pickle.load(open(path + \"test.sighan\" + \"15\" + \"_plus.pkl\", \"rb\"))\n",
    "test_dataset = pickle.load(open(path + \"test.sighan\" + \"15\" + \"_plus.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'wang27k-121941', 'src': '纽约早盘作为基准的低硫轻油，五月份交割价攀升一点三四美元，来到每桶二十八点二五美元，而上周五曾下挫一豪元以上。', 'tgt': '纽约早盘作为基准的低硫轻油，五月份交割价攀升一点三四美元，来到每桶二十八点二五美元，而上周五曾下挫一美元以上。', 'tokens_size': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'src_idx': [101, 5294, 5276, 3193, 4669, 868, 711, 1825, 1114, 4638, 856, 4800, 6768, 3779, 8024, 758, 3299, 819, 769, 1200, 817, 3102, 1285, 671, 4157, 676, 1724, 5401, 1039, 8024, 3341, 1168, 3680, 3446, 753, 1282, 1061, 4157, 753, 758, 5401, 1039, 8024, 5445, 677, 1453, 758, 3295, 678, 2919, 671, 6498, 1039, 809, 677, 511, 102], 'tgt_idx': [101, 5294, 5276, 3193, 4669, 868, 711, 1825, 1114, 4638, 856, 4800, 6768, 3779, 8024, 758, 3299, 819, 769, 1200, 817, 3102, 1285, 671, 4157, 676, 1724, 5401, 1039, 8024, 3341, 1168, 3680, 3446, 753, 1282, 1061, 4157, 753, 758, 5401, 1039, 8024, 5445, 677, 1453, 758, 3295, 678, 2919, 671, 5401, 1039, 809, 677, 511, 102], 'lengths': 55, 'pos': [101, 25, 25, 0, 30, 45, 45, 20, 20, 41, 20, 20, 20, 20, 51, 27, 27, 27, 45, 45, 20, 45, 45, 17, 17, 17, 17, 30, 30, 51, 45, 45, 31, 31, 17, 17, 17, 17, 17, 17, 30, 30, 51, 5, 20, 20, 20, 6, 45, 45, 17, 20, 20, 10, 10, 51, 102], 'seg': [101, 0, 2, 0, 2, 0, 2, 0, 2, 3, 0, 2, 0, 2, 3, 0, 1, 2, 0, 2, 3, 0, 2, 0, 2, 0, 2, 0, 2, 3, 0, 2, 0, 2, 0, 1, 1, 2, 0, 2, 0, 2, 3, 3, 0, 1, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 102], 'error': [101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 102]}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 13649\n"
     ]
    }
   ],
   "source": [
    "_min, _max = min([ min(i[\"tgt_idx\"]) for i in train_dataset]), max( [ max(i[\"tgt_idx\"]) for i in train_dataset])\n",
    "\n",
    "print(_min, _max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, ele in enumerate(test_dataset):\n",
    "    if len(ele[\"src_idx\"]) != len(ele[\"seg\"]):\n",
    "        print(i)\n",
    "        print(len(ele[\"src_idx\"]), len(ele[\"seg\"]))\n",
    "        print(ele[\"src_idx\"], ele[\"seg\"])\n",
    "        break\n",
    "\n",
    "    #if ele[\"src_idx\"].index(101) != 0 or ele[\"src_idx\"].index(102) != len(ele[\"src_idx\"]) - 1:\n",
    "    #    print(i)\n",
    "    #    print(ele[\"src_idx\"].index(101), ele[\"src_idx\"].index(102))\n",
    "    #    print(ele[\"src_idx\"], ele[\"seg\"])\n",
    "    #    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ReaLiSe_multi_task_dataset(args, which=\"15\"):\n",
    "    \"\"\"\n",
    "    For its \n",
    "    \"\"\"\n",
    "    print(\"Loading ReaLiSe with Multi-Task Dataset !\")\n",
    "    print(\"Hint: The Data You loading now is the preprocessed sighan from ReaLise, \")\n",
    "    #ddp_exec(\"os.system('date')\")\n",
    "\n",
    "    path = \"../data/rawdata/sighan/realise/data/\"\n",
    "    import pickle\n",
    "    train_dataset = pickle.load(open(path + \"trainall.times2_plus.pkl\", \"rb\"))\n",
    "    eval_dataset = pickle.load(open(path + \"test.sighan\" + which + \"_plus.pkl\", \"rb\"))\n",
    "    test_dataset = pickle.load(open(path + \"test.sighan\" + which + \"_plus.pkl\", \"rb\"))\n",
    "\n",
    "    print(\"Hint: Using **SIGHAN\" + which + \"** for eval & test !\")\n",
    "\n",
    "    def trans2mydataset(features):\n",
    "        new = []\n",
    "        for feature in features:\n",
    "            tmp = {}\n",
    "            tmp[\"input_ids\"] = feature[\"src_idx\"][:128]\n",
    "            tmp[\"labels\"] = feature[\"tgt_idx\"][:128]\n",
    "            tmp[\"seg_label\"] = feature[\"seg\"][:128]\n",
    "            tmp[\"pos_label\"] = feature[\"pos\"][:128]\n",
    "            tmp[\"idx_label\"] = feature[\"error\"][:128]\n",
    "            tmp[\"attention_mask\"] = ([1] * len(tmp[\"input_ids\"]))[:128]#feature[\"lengths\"])[:128]\n",
    "            new.append(tmp)\n",
    "        \n",
    "        return mydataset(new)\n",
    "\n",
    "    print(\"Loaded successfully !\")\n",
    "    #ddp_exec(\"os.system('date')\")\n",
    "    return trans2mydataset(train_dataset), trans2mydataset(eval_dataset), trans2mydataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ReaLiSe with Multi-Task Dataset !\n",
      "Hint: The Data You loading now is the preprocessed sighan from ReaLise, \n",
      "Hint: Using **SIGHAN15** for eval & test !\n",
      "Loaded successfully !\n"
     ]
    }
   ],
   "source": [
    "train_dataset, eval_dataset, test_dataset = _get_ReaLiSe_multi_task_dataset(None, which=\"15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 872, 1962, 8013, 2769, 3221, 2476, 4263, 3152, 511, 102],\n",
       " 'labels': [101, 872, 1962, 8013, 2769, 3221, 2476, 4263, 3152, 511, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('115')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90bb92497ec70e1ac59ff7125de72f80cb7d571a10b970670d76fc816afd7bfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
