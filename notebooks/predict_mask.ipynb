{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import logging\n",
    "import argparse\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional,Dict, Union, Any, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from transformers import (\n",
    "    DataCollatorForSeq2Seq,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers import Trainer, Seq2SeqTrainer\n",
    "from transformers import TrainingArguments\n",
    "from transformers import trainer_utils, training_args\n",
    "from transformers.trainer_pt_utils import nested_detach\n",
    "from transformers import BertForMaskedLM\n",
    "from transformers.file_utils import PaddingStrategy\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers.tokenization_utils_base import BatchEncoding, PreTrainedTokenizerBase\n",
    "from transformers.training_args import TrainingArguments\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/\")\n",
    "from core import get_magic_dataset, get_metrics, argument_init\n",
    "from lib import subTrainer  \n",
    "from models.bert.modeling_bert_v3 import BertForMaskedLM_v2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMaskedLM_v2.from_pretrained(\"/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/tmp/sighan/bert_MaskedLM_v2_std_mask.epoch20.bs32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset !\n",
      "Thu Dec 16 09:55:52 UTC 2021\n",
      "Loading Abs_Pos Bert SigHan Dataset ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284196/284196 [00:02<00:00, 125311.72it/s]\n",
      "100%|██████████| 600/600 [00:00<00:00, 456730.02it/s]\n",
      "100%|██████████| 1100/1100 [00:00<00:00, 408186.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save cache to cache/sighan_abs_pos_test.\n",
      "Loading Succeed !\n",
      "Thu Dec 16 09:57:08 UTC 2021\n"
     ]
    }
   ],
   "source": [
    "train_dataset, eval_dataset, test_dataset = get_magic_dataset(\"sighan\", \"../\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MyDataCollatorForSeq2Seq:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    label_pad_token_id: int = -100\n",
    "\n",
    "    def __call__(self, features):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        from copy import deepcopy\n",
    "\n",
    "        f_copy = deepcopy(features)\n",
    "\n",
    "        shared_max_length = max([ len(i['input_ids']) for i in f_copy])\n",
    "\n",
    "\n",
    "        for i in range(len(f_copy)):\n",
    "            f_copy[i][\"raw_length\"] = []\n",
    "\n",
    "        for i in range(len(f_copy)):\n",
    "            f_copy[i][\"raw_length\"].append(len(f_copy[i][\"input_ids\"]))\n",
    "\n",
    "        def simple_pad(f_copy, key):\n",
    "            f_key = [ f[key] for f in f_copy ]\n",
    "            if f_key is not None:\n",
    "                max_length = max(len(l) for l in f_key)\n",
    "\n",
    "                padding_side = \"right\"\n",
    "\n",
    "                if key == \"attention_mask\":\n",
    "                    label_pad_token_id = 0\n",
    "                elif key in [\"input_ids\", \"lattice\"]:\n",
    "                    label_pad_token_id = 0\n",
    "                elif key == \"labels\":\n",
    "                    max_length = shared_max_length\n",
    "                    label_pad_token_id= -100\n",
    "                else:\n",
    "                    label_pad_token_id = self.label_pad_token_id \n",
    "\n",
    "                for f in f_copy: \n",
    "                    remainder = [label_pad_token_id] * (max_length - len(f[key]))\n",
    "                    f[key] = (\n",
    "                        f[key] + remainder if padding_side == \"right\" else remainder + f[key]\n",
    "                    )\n",
    "            \n",
    "            return f_copy\n",
    "\n",
    "        for key in [\"input_ids\", \"lattice\", \"labels\", \"attention_mask\"]:\n",
    "            f_copy = simple_pad(f_copy, key)\n",
    "\n",
    "        new = {}\n",
    "\n",
    "        black_list = []\n",
    "\n",
    "        for key in f_copy[0].keys():\n",
    "            if key not in black_list:    \n",
    "                new[key] = []\n",
    "        \n",
    "        for feature in f_copy:\n",
    "            for key in feature.keys():\n",
    "                if key not in black_list:\n",
    "                    new[key].append(feature[key])\n",
    "\n",
    "        for key in new.keys():\n",
    "            if key not in  black_list:\n",
    "                #print(key)\n",
    "            #    new[key] = new[key]\n",
    "                new[key] = torch.tensor(new[key]) \n",
    "\n",
    "        new.pop(\"raw_length\")\n",
    "\n",
    "        return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_model_name_path=\"hfl/chinese-roberta-wwm-ext\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    tokenizer_model_name_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = MyDataCollatorForSeq2Seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model(**pre([test_dataset[0]])).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ = torch.argmax(torch.softmax(p, 2), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 872, 1962,  106, 2769, 3221, 2476, 4263, 3152,  511, 2644, 3221, 5687,\n",
       "         3195, 5687]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:16<00:00,  2.19s/it]\n"
     ]
    }
   ],
   "source": [
    "bs = 32\n",
    "\n",
    "result = []\n",
    "\n",
    "for i in tqdm(range(0, len(test_dataset) // bs + 1)):\n",
    "    batch = test_dataset[ i*32 : (i+1) *32]\n",
    "\n",
    "    logits = model(**pre(batch)).logits\n",
    "\n",
    "    pred = torch.argmax(torch.softmax(logits, 2), -1)\n",
    "\n",
    "    mid = tokenizer.batch_decode(pred)\n",
    "\n",
    "    for j in range(len(batch)):\n",
    "        mid[j] = \"\".join(mid[j].split())[:len(batch[j][\"labels\"])]\n",
    "\n",
    "    result += mid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import write_to\n",
    "write_to(\"no_mask_preds.txt\", \"\\n\".join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [872,\n",
       "  1962,\n",
       "  106,\n",
       "  2769,\n",
       "  3221,\n",
       "  2476,\n",
       "  4263,\n",
       "  3152,\n",
       "  511,\n",
       "  2644,\n",
       "  2356,\n",
       "  2002,\n",
       "  6421,\n",
       "  5687],\n",
       " 'lattice': [0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 4, 6, 6, 6],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': [872, 1962, 106, 2769, 3221, 2476, 4263, 3152, 511],\n",
       " 'sub_length': 9}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90bb92497ec70e1ac59ff7125de72f80cb7d571a10b970670d76fc816afd7bfb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('115': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
