Fri Mar 11 11:39:03 UTC 2022
Fri Mar 11 11:39:03 UTC 2022
Loading Dataset !
Loading Raw Dataset !
Loading SigHan Dataset ...
Traceback (most recent call last):
  File "proto_model.py", line 207, in <module>
    run()
  File "proto_model.py", line 93, in run
    train_dataset, eval_dataset, test_dataset = get_dataset_plus(training_args)#get_dataset(training_args.dataset) 
  File "/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/core.py", line 213, in get_dataset_plus
    return _get_raw_dataset()
  File "/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/core.py", line 256, in _get_raw_dataset
    train_data, eval_data, test_data = load_sighan(path_head="")
  File "/remote-home/xtzhang/anaconda3/envs/117/lib/python3.8/site-packages/fastNLP/core/utils.py", line 357, in wrapper
    results = func(*args, **kwargs)
  File "/remote-home/xtzhang/CTC/CTC2021/SpecialEdition/data/DatasetLoadingHelper.py", line 131, in load_sighan
    train_source_tok = tokenizer.batch_encode_plus(train_source, return_token_type_ids=False)#seems transformers max_length not work
  File "/remote-home/xtzhang/anaconda3/envs/117/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2553, in batch_encode_plus
    return self._batch_encode_plus(
  File "/remote-home/xtzhang/anaconda3/envs/117/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py", line 405, in _batch_encode_plus
    encodings = self._tokenizer.encode_batch(
KeyboardInterrupt
